# ğŸš€ Kafka Data Pipeline Project

> **Python â†’ Confluent Kafka â†’ Druid â†’ Grafana**  
> Complete beginner-friendly data pipeline with Hinglish comments

---

## ğŸ“Š Project Architecture

```
Python Script (Producer)
    â†“
Confluent Kafka (Message Broker)
    â†“
Druid (Data Storage & Analytics)
    â†“
Grafana (Visualization Dashboard)
```

---

## ğŸ¯ What This Project Does

**Real-world Example:** Imagine Zomato tracking food deliveries

1. **Python Script** - Delivery boy ka location aur order status generate karta hai
2. **Kafka** - Ye data real-time mein store karta hai (buffer ki tarah)
3. **Druid** - Historical data store karta hai aur fast queries run karta hai
4. **Grafana** - Beautiful dashboards mein data visualize karta hai

---

## ğŸ“ Project Structure

```
kafka-data-pipeline-project/
â”‚
â”œâ”€â”€ README.md                    # Ye file (project guide)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.sh                     # One-click setup script
â”‚
â”œâ”€â”€ producer/                    # Data generate karne wale scripts
â”‚   â”œâ”€â”€ simple_producer.py       # Basic producer (Task 2)
â”‚   â”œâ”€â”€ catalog_producer.py      # Product catalog producer (Task 1)
â”‚   â””â”€â”€ streaming_producer.py    # Continuous data producer
â”‚
â”œâ”€â”€ consumer/                    # Data consume karne wale scripts
â”‚   â”œâ”€â”€ simple_consumer.py       # Basic consumer
â”‚   â””â”€â”€ druid_consumer.py        # Druid mein data push karne wala
â”‚
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ kafka_config.py          # Kafka settings
â”‚   â””â”€â”€ druid_config.json        # Druid ingestion spec
â”‚
â”œâ”€â”€ data/                        # Sample data files
â”‚   â””â”€â”€ sample_products.json     # Product catalog data
â”‚
â””â”€â”€ docs/                        # Documentation
    â”œâ”€â”€ TASKS.md                 # All 7 tasks explained
    â”œâ”€â”€ SETUP_GUIDE.md           # Step-by-step setup
    â””â”€â”€ TROUBLESHOOTING.md       # Common issues
```

---

## ğŸ“ Learning Tasks (From Screenshot)

### âœ… Task 1: Build a catalog of products
Create a product catalog and send to Kafka

### âœ… Task 2: Getting Started
Basic Kafka producer-consumer setup

### âœ… Task 3: Variables and Functions
Learn Python basics for Kafka

### âœ… Task 4: Recursion/Reusable
Create reusable Kafka functions

### âœ… Task 5: Create a Kafka Producer instance
Initialize Kafka producer properly

### âœ… Task 6: Send Records to Kafka Topic
Send data to Kafka topics

### âœ… Task 7: (From screenshot - not fully visible)
Advanced topics

---

## ğŸš€ Quick Start (5 Minutes)

### Step 1: Install Dependencies
```bash
cd kafka-data-pipeline-project
pip install -r requirements.txt
```

### Step 2: Start Kafka (If Not Running)
```bash
cd ..
./start-kafka.sh
```

### Step 3: Run Simple Producer
```bash
cd kafka-data-pipeline-project
python producer/simple_producer.py
```

### Step 4: Run Simple Consumer (New Terminal)
```bash
cd kafka-data-pipeline-project
python consumer/simple_consumer.py
```

**Working? You'll see messages flowing! ğŸ‰**

---

## ğŸ“š What You'll Learn

### Beginner Level
- âœ… Python basics (variables, functions)
- âœ… Kafka producer setup
- âœ… Kafka consumer setup
- âœ… Sending/receiving messages
- âœ… JSON data handling

### Intermediate Level
- âœ… Confluent Kafka Python client
- âœ… Message serialization
- âœ… Error handling
- âœ… Continuous data streaming
- âœ… Data validation

### Advanced Level
- âœ… Druid integration
- âœ… Real-time analytics
- âœ… Grafana dashboards
- âœ… Production-ready code
- âœ… Performance optimization

---

## ğŸ› ï¸ Technologies Used

| Technology | Purpose | Why? |
|------------|---------|------|
| **Python** | Programming language | Easy to learn, powerful |
| **Confluent Kafka** | Message broker | Industry standard, reliable |
| **Druid** | Analytics database | Fast queries, real-time |
| **Grafana** | Visualization | Beautiful dashboards |

---

## ğŸ“– Detailed Guides

### For Complete Beginners:
1. Read `docs/TASKS.md` - Understand all 7 tasks
2. Read `docs/SETUP_GUIDE.md` - Step-by-step setup
3. Start with `producer/simple_producer.py` - Simplest example
4. Then try `producer/catalog_producer.py` - Real-world example

### For Quick Learners:
1. Install dependencies: `pip install -r requirements.txt`
2. Run producer: `python producer/simple_producer.py`
3. Run consumer: `python consumer/simple_consumer.py`
4. Modify and experiment!

---

## ğŸ¯ Project Goals

By the end of this project, you will:
- âœ… Understand data pipelines
- âœ… Use Kafka for real-time data
- âœ… Write Python producer/consumer
- âœ… Integrate with Druid
- âœ… Create Grafana dashboards
- âœ… Build production-ready code

---

## ğŸ’¡ Real-World Use Cases

### 1. E-commerce (Flipkart/Amazon)
```
Product Updates â†’ Kafka â†’ Druid â†’ Grafana
(Price changes, inventory, orders)
```

### 2. Food Delivery (Zomato/Swiggy)
```
Delivery Tracking â†’ Kafka â†’ Druid â†’ Grafana
(Location, status, ETA)
```

### 3. Ride Sharing (Ola/Uber)
```
Driver Location â†’ Kafka â†’ Druid â†’ Grafana
(Real-time tracking, analytics)
```

---

## ğŸ› Troubleshooting

### Issue 1: Kafka Not Running
```bash
# Check if Kafka is running
lsof -i :9092

# If not, start it
cd ..
./start-kafka.sh
```

### Issue 2: Module Not Found
```bash
# Install dependencies
pip install -r requirements.txt
```

### Issue 3: Connection Refused
```bash
# Check Kafka is on localhost:9092
# Verify in config/kafka_config.py
```

**More Help:** See `docs/TROUBLESHOOTING.md`

---

## ğŸ“ Need Help?

1. Check `docs/TASKS.md` for task explanations
2. Check `docs/SETUP_GUIDE.md` for setup help
3. Check code comments (detailed Hinglish)
4. Check `docs/TROUBLESHOOTING.md` for issues

---

## ğŸ“ Learning Path

### Week 1: Basics
- Day 1-2: Setup & Task 1-2
- Day 3-4: Task 3-4
- Day 5-7: Task 5-6

### Week 2: Integration
- Day 1-3: Druid setup
- Day 4-5: Grafana dashboards
- Day 6-7: Testing & optimization

### Week 3: Advanced
- Build real project
- Add error handling
- Production deployment

---

## âœ… Success Checklist

### Setup Phase
- [ ] Kafka installed and running
- [ ] Python 3.8+ installed
- [ ] Dependencies installed
- [ ] Project structure created

### Learning Phase
- [ ] Task 1: Product catalog completed
- [ ] Task 2: Basic producer/consumer working
- [ ] Task 3: Variables & functions understood
- [ ] Task 4: Reusable code created
- [ ] Task 5: Producer instance working
- [ ] Task 6: Sending records successfully

### Integration Phase
- [ ] Druid installed
- [ ] Data flowing to Druid
- [ ] Grafana installed
- [ ] Dashboard created

### Completion
- [ ] End-to-end pipeline working
- [ ] Can explain each component
- [ ] Can modify and extend
- [ ] Ready for real projects

---

## ğŸŒŸ Next Steps After Completion

1. **Add More Data Sources**
   - Multiple producers
   - Different data types
   - Real APIs integration

2. **Enhance Analytics**
   - Complex Druid queries
   - Multiple Grafana dashboards
   - Alerting setup

3. **Production Ready**
   - Error handling
   - Logging
   - Monitoring
   - Docker deployment

---

## ğŸ“ Notes

- **Language:** All code comments in Hinglish (Latin script only)
- **Difficulty:** Beginner to Intermediate
- **Time:** 2-3 weeks for complete mastery
- **Prerequisites:** Basic Python knowledge helpful but not required

---

**Happy Learning! ğŸš€**

_Agar koi doubt ho, to code comments padho - har line explain ki gayi hai!_
